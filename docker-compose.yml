# medical-ai-hospital/docker-compose.yml
# Production-friendly compose for: Postgres + MCP + Gateway (FastAPI) + Frontend (Next.js)
# - No top-level `version` key.
# - Healthchecks for each service.
# - Secrets via `.env` (copy from .env.template and fill in).
# - Log rotation and restart policies.
# - Isolated networks for backend/edge tiers.

services:
  db:
    image: postgres:15
    container_name: db
    restart: unless-stopped
    env_file:
      - .env
    stop_signal: SIGINT
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./db/10_init.sql:/docker-entrypoint-initdb.d/10_init.sql:ro
      - ./db/20_seed.sql:/docker-entrypoint-initdb.d/20_seed.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-mcp_user} -d ${POSTGRES_DB:-medical_db}"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - backend

  mcp:
    image: ghcr.io/ruslanmv/medical-mcp-toolkit:latest
    container_name: mcp
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp
    env_file:
      - .env
    ports:
      - "${MCP_PORT:-9090}:8080"
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.25"
          memory: 512M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - backend

  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    container_name: gateway
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp
    env_file:
      - .env
    ports:
      - "${GATEWAY_PORT:-8080}:8080"
    depends_on:
      db:
        condition: service_healthy
      mcp:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.25"
          memory: 512M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - backend
      - edge

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    restart: unless-stopped
    stop_grace_period: 30s
    env_file:
      - .env
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    depends_on:
      gateway:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:3000/ >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.25"
          memory: 512M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - edge

volumes:
  db_data:
    name: medical_ai_db_data

networks:
  backend:
    driver: bridge
    name: medical_ai_backend
  edge:
    driver: bridge
    name: medical_ai_edge
